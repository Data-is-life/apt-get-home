{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:37.291299Z",
     "start_time": "2018-09-17T21:15:36.814398Z"
    }
   },
   "outputs": [],
   "source": [
    "import re as re\n",
    "import time\n",
    "import zipcode\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:38.456397Z",
     "start_time": "2018-09-17T21:15:38.438386Z"
    }
   },
   "outputs": [],
   "source": [
    "def zipcodes_list(st_items):\n",
    "    # If st_items is a single zipcode string.\n",
    "    if isinstance(st_items, str):\n",
    "        zc_objects = zipcode.islike(st_items)\n",
    "        output = [str(i).split(\" \", 1)[1].split(\">\")[0] for i in zc_objects]\n",
    "    # If st_items is a list of zipcode strings.\n",
    "    elif isinstance(st_items, list):\n",
    "        zc_objects = [n for i in st_items for n in zipcode.islike(str(i))]\n",
    "        output = [str(i).split(\" \", 1)[1].split(\">\")[0] for i in zc_objects]\n",
    "    else:\n",
    "        raise ValueError(\"arg 'st_items' must be of type str or list\")\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:39.086803Z",
     "start_time": "2018-09-17T21:15:39.069545Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_driver(file_path):\n",
    "    # Starting maximized fixes https://github.com/ChrisMuir/Zillow/issues/1\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(executable_path=file_path, \n",
    "                              chrome_options=options)\n",
    "    driver.wait = WebDriverWait(driver, 10)\n",
    "    return(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:39.608443Z",
     "start_time": "2018-09-17T21:15:39.592571Z"
    }
   },
   "outputs": [],
   "source": [
    "def _is_element_displayed(driver, elem_text, elem_type):\n",
    "    if elem_type == \"class\":\n",
    "        try:\n",
    "            out = driver.find_element_by_class_name(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    elif elem_type == \"css\":\n",
    "        try:\n",
    "            out = driver.find_element_by_css_selector(elem_text).is_displayed()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            out = False\n",
    "    else:\n",
    "        raise ValueError(\"arg 'elem_type' must be either 'class' or 'css'\")\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:40.014254Z",
     "start_time": "2018-09-17T21:15:39.998795Z"
    }
   },
   "outputs": [],
   "source": [
    "def _pause_for_captcha(driver):\n",
    "    while True:\n",
    "        time.sleep(30)\n",
    "        if not _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:40.311333Z",
     "start_time": "2018-09-17T21:15:40.292315Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_for_captcha(driver):\n",
    "    if _is_element_displayed(driver, \"captcha-container\", \"class\"):\n",
    "        print(\"\\nCAPTCHA!\\n\"\\\n",
    "              \"Manually complete the captcha requirements.\")\n",
    "        _pause_for_captcha(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:40.521297Z",
     "start_time": "2018-09-17T21:15:40.498329Z"
    }
   },
   "outputs": [],
   "source": [
    "def navigate_to_website(driver, site):\n",
    "    driver.get(site)\n",
    "    # Check to make sure a captcha page is not displayed.\n",
    "    check_for_captcha(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:40.722889Z",
     "start_time": "2018-09-17T21:15:40.703343Z"
    }
   },
   "outputs": [],
   "source": [
    "def enter_search_term(driver, search_term):\n",
    "    if not isinstance(search_term, str):\n",
    "        search_term = str(search_term)\n",
    "    try:\n",
    "        search_bar = driver.wait.until(EC.presence_of_element_located(\n",
    "            (By.ID, \"citystatezip\")))\n",
    "        button = driver.wait.until(EC.element_to_be_clickable(\n",
    "            (By.CLASS_NAME, \"zsg-icon-searchglass\")))\n",
    "        search_bar.clear()\n",
    "        time.sleep(3)\n",
    "        search_bar.send_keys(search_term)\n",
    "        time.sleep(3)\n",
    "        button.click()\n",
    "        time.sleep(3)\n",
    "        return(True)\n",
    "    except (TimeoutException, NoSuchElementException):\n",
    "        return(False)\n",
    "    # Check to make sure a captcha page is not displayed.\n",
    "    check_for_captcha(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:40.914031Z",
     "start_time": "2018-09-17T21:15:40.898044Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_for_no_results(driver):\n",
    "    # Check to see if the \"zoom out\" msg exists (an indication that no results\n",
    "    # were returned from the search).\n",
    "    no_results = _is_element_displayed(driver, \".zoom-out-message\", \"css\")\n",
    "    # If the zoom-out msg is not displayed, check for \"invalid zip\" msg.\n",
    "    if not no_results:\n",
    "        no_results = _is_element_displayed(driver, \"zsg-icon-x-thick\", \"class\")\n",
    "    # Check to make sure a captcha page is not displayed.\n",
    "    check_for_captcha(driver)\n",
    "    return(no_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:41.121929Z",
     "start_time": "2018-09-17T21:15:41.104235Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_html(driver):\n",
    "    output = []\n",
    "    keep_going = True\n",
    "    while keep_going:\n",
    "        # Pull page HTML\n",
    "        try:\n",
    "            output.append(driver.page_source)\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        # Check to see if a \"next page\" link exists.\n",
    "        keep_going = _is_element_displayed(driver, \"zsg-pagination-next\", \n",
    "                                           \"class\")\n",
    "        if keep_going:\n",
    "            # Test to ensure the \"updating results\" image isnt displayed. \n",
    "            # Will try up to 5 times before giving up, with a 5 second wait \n",
    "            # between each try.             \n",
    "            tries = 5\n",
    "            cover = _is_element_displayed(driver, \n",
    "                                          \"list-loading-message-cover\", \n",
    "                                          \"class\")\n",
    "            while cover and tries > 0:\n",
    "                time.sleep(5)\n",
    "                tries -= 1\n",
    "                cover = _is_element_displayed(driver, \n",
    "                                              \"list-loading-message-cover\", \n",
    "                                              \"class\")\n",
    "            # If the \"updating results\" image is confirmed to be gone \n",
    "            # (cover == False), click next page. Otherwise, give up on trying \n",
    "            # to click thru to the next page of house results, and return the \n",
    "            # results that have been scraped up to the current page.\n",
    "            if not cover:\n",
    "                try:\n",
    "                    driver.wait.until(EC.element_to_be_clickable(\n",
    "                        (By.CLASS_NAME, \"zsg-pagination-next\"))).click()\n",
    "                    time.sleep(3)\n",
    "                    # Check to make sure a captcha page is not displayed.\n",
    "                    check_for_captcha(driver)\n",
    "                except TimeoutException:\n",
    "                    keep_going = False\n",
    "            else:\n",
    "                keep_going = False\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:41.266416Z",
     "start_time": "2018-09-17T21:15:41.251422Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_listings(list_obj):\n",
    "    output = []\n",
    "    for i in list_obj:\n",
    "        htmlSplit = i.split('\" id=\"zpid_')[1:]\n",
    "        output += htmlSplit\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:41.404468Z",
     "start_time": "2018-09-17T21:15:41.389060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for testing if an object is \"empty\" or not.\n",
    "def _is_empty(obj):\n",
    "    if any([len(obj) == 0, obj == \"null\"]):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:41.560271Z",
     "start_time": "2018-09-17T21:15:41.544989Z"
    }
   },
   "outputs": [],
   "source": [
    "# For most listings, card_info will contain info on number of bedrooms, \n",
    "# number of bathrooms, square footage, and sometimes price.\n",
    "def get_card_info(soup_obj):\n",
    "    try:\n",
    "        card = soup_obj.find(\n",
    "            \"span\", {\"class\" : \"zsg-photo-card-info\"}).get_text().split(u\" \\xb7 \")\n",
    "    except (ValueError, AttributeError):\n",
    "        card = \"NA\"\n",
    "    if _is_empty(card):\n",
    "        card = \"NA\"\n",
    "    return(card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:41.709364Z",
     "start_time": "2018-09-17T21:15:41.692898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_street_address(soup_obj):\n",
    "    try:\n",
    "        street = soup_obj.find(\n",
    "            \"span\", {\"itemprop\" : \"streetAddress\"}).get_text().strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        street = \"NA\"\n",
    "    if _is_empty(street):\n",
    "        street = \"NA\"\n",
    "    return(street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:42.695417Z",
     "start_time": "2018-09-17T21:15:42.679290Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_city(soup_obj):\n",
    "    try:\n",
    "        city = soup_obj.find(\n",
    "            \"span\", {\"itemprop\" : \"addressLocality\"}).get_text().strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        city = \"NA\"\n",
    "    if _is_empty(city):\n",
    "        city = \"NA\"\n",
    "    return(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:42.900516Z",
     "start_time": "2018-09-17T21:15:42.878666Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_state(soup_obj):\n",
    "    try:\n",
    "        state = soup_obj.find(\n",
    "            \"span\", {\"itemprop\" : \"addressRegion\"}).get_text().strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        state = \"NA\"\n",
    "    if _is_empty(state):\n",
    "        state = \"NA\"\n",
    "    return(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:43.047797Z",
     "start_time": "2018-09-17T21:15:43.032848Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zipcode(soup_obj):\n",
    "    try:\n",
    "        zipcode = soup_obj.find(\n",
    "            \"span\", {\"itemprop\" : \"postalCode\"}).get_text().strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        zipcode = \"NA\"\n",
    "    if _is_empty(zipcode):\n",
    "        zipcode = \"NA\"\n",
    "    return(zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:43.904880Z",
     "start_time": "2018-09-17T21:15:43.885357Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_price(soup_obj, list_obj):\n",
    "    # Look for price within the BeautifulSoup object.\n",
    "    try:\n",
    "        price = soup_obj.find(\n",
    "            \"span\", {\"class\" : \"zsg-photo-card-price\"}).get_text().strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        # If that fails, look for price within list_obj (object \"card_info\").\n",
    "        try:\n",
    "            price = [n for n in list_obj \n",
    "                         if any([\"$\" in n, \"K\" in n, \"k\" in n])]\n",
    "            if len(price) > 0:\n",
    "                price = price[0].split(\" \")\n",
    "                price = [n for n in price if re.search(\"\\d\", n)]\n",
    "                if len(price[0]) > 0:\n",
    "                    price = price[0]\n",
    "                else:\n",
    "                    price = \"NA\"\n",
    "            else:\n",
    "                price = \"NA\"\n",
    "        except (ValueError, AttributeError):\n",
    "            price = \"NA\"\n",
    "    if _is_empty(price):\n",
    "        price = \"NA\"\n",
    "    if price != \"NA\":\n",
    "        # Transformations to the price string.\n",
    "        price = price.replace(\",\", \"\").replace(\"+\", \"\").replace(\"$\", \"\").lower()\n",
    "        if \"k\" in price:\n",
    "            price = price.split(\"k\")[0].strip()\n",
    "            price = price + \"000\"\n",
    "        if \"m\" in price:\n",
    "            price = price.split(\"m\")[0].strip()\n",
    "            if \".\" not in price:\n",
    "                price = price + \"000000\"\n",
    "            else:\n",
    "                pricelen = len(price.split(\".\")[0]) + 6\n",
    "                price = price.replace(\".\", \"\")\n",
    "                price = price + ((pricelen - len(price)) * \"0\")\n",
    "        if _is_empty(price):\n",
    "            price = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:44.543260Z",
     "start_time": "2018-09-17T21:15:44.524241Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sqft(list_obj):\n",
    "    sqft = [n for n in list_obj if \"sqft\" in n]\n",
    "    if len(sqft) > 0:\n",
    "        try:\n",
    "            sqft = float(\n",
    "                sqft[0].split(\"sqft\")[0].strip().replace(\",\", \"\").replace(\"+\", \"\")\n",
    "            )\n",
    "        except (ValueError, IndexError):\n",
    "            sqft = \"NA\"\n",
    "        if sqft == 0:\n",
    "            sqft = \"NA\"\n",
    "    else:\n",
    "        sqft = \"NA\"\n",
    "    return(sqft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:45.059243Z",
     "start_time": "2018-09-17T21:15:45.042003Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bedrooms(list_obj):\n",
    "    beds = [n for n in list_obj if any([\"bd\" in n, \"tudio\" in n])]\n",
    "    if len(beds) > 0:\n",
    "        beds = beds[0].lower()\n",
    "        if beds == \"studio\":\n",
    "            return(0.0)\n",
    "        try:\n",
    "            beds = float(beds.split(\"bd\")[0].strip())\n",
    "        except (ValueError, IndexError):\n",
    "            beds = \"NA\"\n",
    "    else:\n",
    "        beds = \"NA\"\n",
    "    return(beds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:45.659799Z",
     "start_time": "2018-09-17T21:15:45.641771Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bathrooms(list_obj):\n",
    "    baths = [n for n in list_obj if \"ba\" in n]\n",
    "    if len(baths) > 0:\n",
    "        try:\n",
    "            baths = float(baths[0].split(\"ba\")[0].strip())\n",
    "        except (ValueError, IndexError):\n",
    "            baths = \"NA\"\n",
    "        if baths == 0:\n",
    "            baths = \"NA\"\n",
    "    else:\n",
    "        baths = \"NA\"\n",
    "    return(baths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:46.128828Z",
     "start_time": "2018-09-17T21:15:46.111232Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_days_on_market(soup_obj):\n",
    "    try:\n",
    "        dom = soup_obj.find_all(\n",
    "            \"ul\", {\"class\" : \"zsg-list_inline zsg-photo-card-badge\"})\n",
    "        if dom is not None:\n",
    "            dom = [n.get_text().strip().lower() for n in dom]\n",
    "            dom = [n for n in dom if \"zillow\" in n]\n",
    "            if len(dom) > 0:\n",
    "                dom = int(dom[0].split(\" \")[0])\n",
    "            else:\n",
    "                dom = \"NA\"\n",
    "        else:\n",
    "            dom = \"NA\"\n",
    "    except (ValueError, AttributeError):\n",
    "        dom = \"NA\"\n",
    "    return(dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:46.752830Z",
     "start_time": "2018-09-17T21:15:46.736200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sale_type(soup_obj):\n",
    "    try:\n",
    "        sale_type = soup_obj.find(\n",
    "            \"span\", {\"class\" : \"zsg-photo-card-status\"}).get_text().strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        sale_type = \"NA\"\n",
    "    if _is_empty(sale_type):\n",
    "        sale_type = \"NA\"\n",
    "    return(sale_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:47.246491Z",
     "start_time": "2018-09-17T21:15:47.224928Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_url(soup_obj):\n",
    "    # Try to find url in the BeautifulSoup object.\n",
    "    href = [n[\"href\"] for n in soup_obj.find_all(\"a\", href = True)]\n",
    "    url = [i for i in href if \"homedetails\" in i]\n",
    "    if len(url) > 0:\n",
    "        url = \"http://www.zillow.com/homes/for_sale/\" + url[0]\n",
    "    else:\n",
    "        # If that fails, contruct the url from the zpid of the listing.\n",
    "        url = [i for i in href if \"zpid\" in i and \"avorite\" not in i]\n",
    "        if len(url) > 0:\n",
    "            zpid = re.findall(r\"\\d{8,10}\", url[0])\n",
    "            if zpid is not None and len(zpid) > 0:\n",
    "                url = \"http://www.zillow.com/homes/for_sale/\" \\\n",
    "                        + str(zpid[0]) \\\n",
    "                        + \"_zpid/any_days/globalrelevanceex_sort/29.759534,\" \\\n",
    "                        + \"-95.335321,29.675003,-95.502863_rect/12_zm/\"\n",
    "            else:\n",
    "                url = \"NA\"\n",
    "        else:\n",
    "            url = \"NA\"\n",
    "    return(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:48.168253Z",
     "start_time": "2018-09-17T21:15:48.153686Z"
    }
   },
   "outputs": [],
   "source": [
    "def close_connection(driver):\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T21:15:49.092992Z",
     "start_time": "2018-09-17T21:15:48.986406Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8dff17b3f3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Param st_items can be either a list of zipcode strings, or a single zipcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzipcodes_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"100\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"770\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Initialize the webdriver.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'zl' is not defined"
     ]
    }
   ],
   "source": [
    "# Create list of search terms.\n",
    "# Function zipcodes_list() creates a list of US zip codes that will be \n",
    "# passed to the scraper. For example, st = zipcodes_list([\"10\", \"11\", \"606\"])  \n",
    "# will yield every US zip code that begins with \"10\", begins with \"11\", or \n",
    "# begins with \"606\", as a list object.\n",
    "# I recommend using zip codes, as they seem to be the best option for catching\n",
    "# as many house listings as possible. If you want to use search terms other \n",
    "# than zip codes, simply skip running zipcodes_list() function below, and add \n",
    "# a line of code to manually assign values to object st, for example:\n",
    "# st = [\"Chicago\", \"New Haven, CT\", \"77005\", \"Jacksonville, FL\"]\n",
    "# Keep in mind that, for each search term, the number of listings scraped is \n",
    "# capped at 520, so in using a search term like \"Chicago\" the scraper would \n",
    "# end up missing most of the results.\n",
    "# Param st_items can be either a list of zipcode strings, or a single zipcode \n",
    "# string.\n",
    "st = zl.zipcodes_list(st_items = [\"100\", \"770\"])\n",
    "\n",
    "# Initialize the webdriver.\n",
    "driver = zl.init_driver(\"C:/Users/username/chromedriver.exe\")\n",
    "\n",
    "# Go to www.zillow.com/homes\n",
    "zl.navigate_to_website(driver, \"http://www.zillow.com/homes\")\n",
    "\n",
    "# Click the \"buy\" button.\n",
    "zl.click_buy_button(driver)\n",
    "\n",
    "# Get total number of search terms.\n",
    "num_search_terms = len(st)\n",
    "\n",
    "# Initialize list obj that will house all scraped data.\n",
    "output_data = []\n",
    "\n",
    "# Start the scraping.\n",
    "for idx, term in enumerate(st):\n",
    "    # Enter search term and execute search.\n",
    "    if zl.enter_search_term(driver, term):\n",
    "        print(\"Entering search term %s of %s\" % \n",
    "              (str(idx + 1), str(num_search_terms)))\n",
    "    else:\n",
    "        print(\"Search term %s failed, moving on to next search term\\n***\" % \n",
    "              str(idx + 1))\n",
    "        continue\n",
    "\n",
    "    # Check to see if any results were returned from the search.\n",
    "    # If there were none, move onto the next search.\n",
    "    if zl.test_for_no_results(driver):\n",
    "        print(\"Search %s returned zero results. Moving on to next search\\n***\" %\n",
    "              str(term))\n",
    "        continue\n",
    "\n",
    "    # Pull the html for each page of search results. Zillow caps results at \n",
    "    # 20 pages, each page can contain 26 home listings, thus the cap on home \n",
    "    # listings per search is 520.\n",
    "    raw_data = zl.get_html(driver)\n",
    "    print(\"%s pages of listings found\" % str(len(raw_data)))\n",
    "\n",
    "    # Take the extracted HTML and split it up by individual home listings.\n",
    "    listings = zl.get_listings(raw_data)\n",
    "    print(\"%s home listings scraped\\n***\" % str(len(listings)))\n",
    "\n",
    "    # For each home listing, extract the 11 variables that will populate that \n",
    "    # specific observation within the output dataframe.\n",
    "    for home in listings:\n",
    "        soup = BeautifulSoup(home, \"lxml\")\n",
    "        new_obs = []\n",
    "\n",
    "        # List that contains number of beds, baths, and total sqft (and \n",
    "        # sometimes price as well).\n",
    "        card_info = zl.get_card_info(soup)\n",
    "\n",
    "        # Street Address\n",
    "        new_obs.append(zl.get_street_address(soup))\n",
    "        \n",
    "        # City\n",
    "        new_obs.append(zl.get_city(soup))\n",
    "        \n",
    "        # State\n",
    "        new_obs.append(zl.get_state(soup))\n",
    "        \n",
    "        # Zipcode\n",
    "        new_obs.append(zl.get_zipcode(soup))\n",
    "        \n",
    "        # Price\n",
    "        new_obs.append(zl.get_price(soup, card_info))\n",
    "        \n",
    "        # Sqft\n",
    "        new_obs.append(zl.get_sqft(card_info))\n",
    "        \n",
    "        # Bedrooms\n",
    "        new_obs.append(zl.get_bedrooms(card_info))\n",
    "        \n",
    "        # Bathrooms\n",
    "        new_obs.append(zl.get_bathrooms(card_info))\n",
    "        \n",
    "        # Days on the Market/Zillow\n",
    "        new_obs.append(zl.get_days_on_market(soup))\n",
    "        \n",
    "        # Sale Type (House for Sale, New Construction, Foreclosure, etc.)\n",
    "        new_obs.append(zl.get_sale_type(soup))\n",
    "        \n",
    "        # URL for each house listing\n",
    "        new_obs.append(zl.get_url(soup))\n",
    "        \n",
    "        # Append new_obs to list output_data.\n",
    "        output_data.append(new_obs)\n",
    "\n",
    "# Close the webdriver connection.\n",
    "zl.close_connection(driver)\n",
    "\n",
    "# Write data to data frame, then to CSV file.\n",
    "file_name = \"%s_%s.csv\" % (str(time.strftime(\"%Y-%m-%d\")), \n",
    "                           str(time.strftime(\"%H%M%S\")))\n",
    "columns = [\"address\", \"city\", \"state\", \"zip\", \"price\", \"sqft\", \"bedrooms\", \n",
    "           \"bathrooms\", \"days_on_zillow\", \"sale_type\", \"url\"]\n",
    "pd.DataFrame(output_data, columns = columns).to_csv(\n",
    "    file_name, index = False, encoding = \"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties = pd.read_csv('list-counties-us-436j.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County or equivalent</th>\n",
       "      <th>State or district</th>\n",
       "      <th>Core Based Statistical Area</th>\n",
       "      <th>Combined Statistical Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montgomery, AL Metropolitan Statistical Area</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL Micropolitan Statist...</td>\n",
       "      <td>Mobile-Daphne-Fairhope, AL Combined Statistica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Birmingham-Hoover, AL Metropolitan Statistical...</td>\n",
       "      <td>Birmingham-Hoover-Talladega, AL Combined Stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Birmingham-Hoover, AL Metropolitan Statistical...</td>\n",
       "      <td>Birmingham-Hoover-Talladega, AL Combined Stati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  County or equivalent State or district  \\\n",
       "0       Autauga County           Alabama   \n",
       "1       Baldwin County           Alabama   \n",
       "2       Barbour County           Alabama   \n",
       "3          Bibb County           Alabama   \n",
       "4        Blount County           Alabama   \n",
       "\n",
       "                         Core Based Statistical Area  \\\n",
       "0       Montgomery, AL Metropolitan Statistical Area   \n",
       "1  Daphne-Fairhope-Foley, AL Micropolitan Statist...   \n",
       "2                                                NaN   \n",
       "3  Birmingham-Hoover, AL Metropolitan Statistical...   \n",
       "4  Birmingham-Hoover, AL Metropolitan Statistical...   \n",
       "\n",
       "                           Combined Statistical Area  \n",
       "0                                                NaN  \n",
       "1  Mobile-Daphne-Fairhope, AL Combined Statistica...  \n",
       "2                                                NaN  \n",
       "3  Birmingham-Hoover-Talladega, AL Combined Stati...  \n",
       "4  Birmingham-Hoover-Talladega, AL Combined Stati...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [num for num in df_counties['County or equivalent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
