{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T20:46:10.870612Z",
     "start_time": "2018-10-25T20:46:10.401145Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import time, re, ast, sys, urllib, random, string, requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from selenium.webdriver.firefox.webdriver import FirefoxProfile\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError, URLError\n",
    "from itertools import cycle\n",
    "from header_list import user_agent_list\n",
    "from proxies_list import proxies_list_\n",
    "from initial_scrapper_function import *\n",
    "from parser_functions import *\n",
    "from list_df_functions import *\n",
    "from search_url_gen import *\n",
    "from get_search_url import *\n",
    "from get_results import *\n",
    "ua = user_agent_list\n",
    "proxies = proxies_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T20:46:12.746395Z",
     "start_time": "2018-10-25T20:46:12.730022Z"
    }
   },
   "outputs": [],
   "source": [
    "proxies = ['65.126.127.202:37005', '209.97.158.105:3128', '209.97.233.3:61268', '50.224.173.189:8080',\n",
    "           '50.224.173.190:8080', '216.163.15.34:52055', '73.109.32.51:54794', '96.91.251.185:37033',\n",
    "           '50.197.38.230:60724', '72.35.40.34:8080', '50.253.186.195:61019', '12.183.155.91:39828',\n",
    "           '70.183.205.174:40964', '199.27.95.234:40847', '64.183.32.218:49425', '206.130.141.255:46978',\n",
    "           '67.198.99.138:60810', '140.227.60.114:3128', '205.169.145.130:39438', '70.89.33.14:32246',\n",
    "           '162.17.233.218:61104', '142.147.112.246:59640', '96.74.27.161:32784', '45.32.166.253:8118',\n",
    "           '97.68.17.66:53281', '50.224.173.179:8080', '72.223.107.81:32120', '216.201.235.94:8080',\n",
    "           '71.43.26.18:46024', '63.98.248.179:53281', '24.162.164.231:61354', '50.205.213.17:39860',\n",
    "           '209.105.225.218:53281', '67.217.116.111:8080', '76.109.168.55:8080', '104.139.71.127:58366',\n",
    "           '174.71.143.254:60197', '24.227.222.4:53281', '12.218.209.130:53281', '205.145.146.18:37854',\n",
    "           '184.177.165.96:30622', '12.131.182.225:38606', '199.231.171.106:53281', '69.206.51.199:61751',\n",
    "           '23.242.11.35:39739', '38.134.10.106:53281', '50.252.132.229:31116', '12.189.124.100:31171',\n",
    "           '52.124.6.226:41759', '37.61.224.105:8001', '208.75.19.142:8888', '50.236.148.254:39970',\n",
    "           '138.68.251.89:39874', '12.175.211.121:59669', '63.246.49.113:8080', '65.98.182.126:59988',\n",
    "           '75.71.180.197:50916', '12.7.109.251:40454', '104.139.105.234:35633', '45.30.170.25:8888',\n",
    "           '12.7.109.250:50524', '216.21.161.185:53293', '50.224.87.210:53294']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-25T21:01:46.478457Z",
     "start_time": "2018-10-25T20:46:19.810148Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Fast: 1.3253509998321533\n",
      "#2 Delete: 0.10163354873657227\n",
      "#3 Delete: 0.06954312324523926\n",
      "#4 Keep: 6.432597875595093\n",
      "#5 Keep: 8.95765209197998\n",
      "#6 Keep: 8.585253715515137\n",
      "#7 Delete: 0.15608906745910645\n",
      "#8 Delete: 0.2531857490539551\n",
      "#9 Keep: 6.192028522491455\n",
      "#10 Keep: 3.92012619972229\n",
      "#11 Delete: 1.1594972610473633\n",
      "#12 Fast: 1.7833900451660156\n",
      "#13 Delete: 0.07641816139221191\n",
      "#14 Delete: 0.1633925437927246\n",
      "#15 SUPERFAST: 0.6729669570922852\n",
      "#16 Delete: 0.08942246437072754\n",
      "#17 Snail: 38.688780069351196\n",
      "#18 Fast: 1.696824073791504\n",
      "#19 Slow: 18.004807949066162\n",
      "#20 Decide: 11.73720383644104\n",
      "#21 Keep: 5.620624542236328\n",
      "#22 Delete: 129.36334443092346\n",
      "#23 Slow: 18.509373664855957\n",
      "#24 Keep: 5.121981620788574\n",
      "#25 Fast: 2.0633509159088135\n",
      "#26 Fast: 2.7413065433502197\n",
      "#27 Keep: 8.097559928894043\n",
      "#28 Keep: 4.703843832015991\n",
      "#29 Delete: 3.273735523223877\n",
      "#30 Snail: 26.217984437942505\n",
      "#31 Delete: 0.12587738037109375\n",
      "#32 Keep: 8.889691352844238\n",
      "#33 Decide: 11.856401443481445\n",
      "#34 Keep: 5.582224369049072\n",
      "#35 Keep: 5.8854286670684814\n",
      "#36 Decide: 14.157030820846558\n",
      "#37 Keep: 3.887681245803833\n",
      "#38 Decide: 12.92610216140747\n",
      "#39 Snail: 25.12067985534668\n",
      "#40 Fast: 1.2786879539489746\n",
      "#41 Keep: 7.161853790283203\n",
      "#42 Decide: 10.033393621444702\n",
      "#43 Keep: 8.605429649353027\n",
      "#44 Delete: 4.7180352210998535\n",
      "#45 Keep: 7.068370580673218\n",
      "#46 Delete: 4.194451808929443\n",
      "#47 Decide: 10.341480731964111\n",
      "#48 Delete: 0.3039584159851074\n",
      "#49 Delete: 0.44825124740600586\n",
      "#50 Delete: 130.74481010437012\n",
      "#51 Snail: 66.67666912078857\n",
      "#52 Slow: 18.451584815979004\n",
      "#53 Snail: 39.34212112426758\n",
      "#54 SUPERFAST: 0.6315872669219971\n",
      "#55 Delete: 130.8980073928833\n",
      "#56 Decide: 14.807499885559082\n",
      "#57 Snail: 24.025182962417603\n",
      "#58 Decide: 13.510994911193848\n",
      "#59 Delete: 10.74359655380249\n",
      "#60 Decide: 13.949972152709961\n",
      "#61 Keep: 3.8437788486480713\n",
      "#62 Delete: 0.36969614028930664\n",
      "#63 Delete: 0.2761719226837158\n"
     ]
    }
   ],
   "source": [
    "def proxie_check(proxies):\n",
    "\n",
    "    sprfst = []\n",
    "    fst = []\n",
    "    keep = []\n",
    "    meh = []\n",
    "    slw = []\n",
    "    snl = []\n",
    "    usls = []\n",
    "    url = 'https://httpbin.org/ip'\n",
    "    for i in range(1, (len(proxies))+1):\n",
    "        proxy = proxies[i-1]\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url, proxies={\"http\": proxy, \"https\": proxy})\n",
    "            \n",
    "            total_time = time.time()-start_time\n",
    "\n",
    "            if total_time <= 1.00:\n",
    "                sprfst.append(i)\n",
    "                print(\n",
    "                    f'#{i} SUPERFAST: {total_time}')\n",
    "            elif total_time <= 3.00:\n",
    "                fst.append(i)\n",
    "                print(f'#{i} Fast: {total_time}')\n",
    "            elif total_time <= 10.00:\n",
    "                keep.append(i)\n",
    "                print(f'#{i} Keep: {total_time}')\n",
    "            elif total_time <= 15.00:\n",
    "                meh.append(i)\n",
    "                print(f'#{i} Decide: {total_time}')\n",
    "            elif total_time <= 20.00:\n",
    "                slw.append(i)\n",
    "                print(f'#{i} Slow: {total_time}')\n",
    "            else:\n",
    "                snl.append(i)\n",
    "                print(f'#{i} Snail: {total_time}')\n",
    "        except:\n",
    "            total_time = time.time()-start_time\n",
    "            usls.append(i)\n",
    "            print(f'#{i} Delete: {total_time}')\n",
    "    \n",
    "    all_proxs = {}\n",
    "    all_proxs['superfast'] = sprfst\n",
    "    all_proxs['fast'] = fst\n",
    "    all_proxs['keep'] = keep\n",
    "    all_proxs['decide'] = meh\n",
    "    all_proxs['slow'] = slw\n",
    "    all_proxs['snail'] = snl\n",
    "    all_proxs['delete'] = usls\n",
    "    return all_proxs\n",
    "\n",
    "all_proxs = proxie_check(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T21:45:23.731968Z",
     "start_time": "2018-10-24T21:45:23.712118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T21:45:24.757324Z",
     "start_time": "2018-10-24T21:45:24.618348Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../Data/zip_url_search_list.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ad845b944ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcities_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/zip_url_search_list.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcity_url_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcities_url\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../Data/zip_url_search_list.csv' does not exist"
     ]
    }
   ],
   "source": [
    "cities_url = pd.read_csv('../Data/zip_url_search_list.csv', header=None)\n",
    "city_url_list = cities_url[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T21:19:50.023062Z",
     "start_time": "2018-10-12T21:19:50.001152Z"
    }
   },
   "outputs": [],
   "source": [
    "prop_count_per_city_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T02:55:38.303174Z",
     "start_time": "2018-10-13T02:55:38.280230Z"
    }
   },
   "outputs": [],
   "source": [
    "def session_creator(proxy, ua, url):\n",
    "    header = random.sample(ua, 1)[0]\n",
    "    session = requests.Session()\n",
    "    session.proxies = {\"http\": proxy, \"https\": proxy}\n",
    "    req = session.get(url, headers=header)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:26:51.570032Z",
     "start_time": "2018-10-13T02:55:41.659192Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_url_list = random.sample(city_url_list, len(city_url_list))\n",
    "def areas_extractor_url(proxies, prp_list, url_list, ua):\n",
    "    proxy = random.sample(proxies, 1)[0]\n",
    "    print(proxies.index(proxy))\n",
    "    print(proxy)\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            soup = session_creator(proxy, ua, url)\n",
    "            time.sleep(random.uniform(1.5, 3.8))\n",
    "            all_count = soup.find('meta', {'name': 'description'})\n",
    "            print(all_count.text)\n",
    "            print(time.time() - start_time)\n",
    "            if len(all_count) > 0:\n",
    "                prp_list.append(all_count)\n",
    "                url_list.remove(url)\n",
    "                print(f'url left: {len(url_list)}')\n",
    "                print(f'url done: {len(prp_list)}')\n",
    "            else:\n",
    "                print('captcha')\n",
    "        except:\n",
    "            print(\"Connnection error\")\n",
    "            proxies.remove(proxy)\n",
    "            print(len(proxies))\n",
    "            return prp_list, url_list\n",
    "    return prp_list, url_list\n",
    "\n",
    "\n",
    "while (len(proxies)>0) and (len(city_url_list)>0):\n",
    "    prop_count_per_city_list, city_url_list = areas_extractor_url(\n",
    "        proxies, prop_count_per_city_list, city_url_list, ua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:27:12.134857Z",
     "start_time": "2018-10-13T03:27:12.120069Z"
    }
   },
   "outputs": [],
   "source": [
    "len(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:48:53.169168Z",
     "start_time": "2018-10-13T03:48:53.150367Z"
    }
   },
   "outputs": [],
   "source": [
    "total_act_pend_per_city = []\n",
    "for num in prop_count_per_city_list:\n",
    "    for i in num:\n",
    "        total_act_pend_per_city.extend((re.findall(r'\\d+', i['content'].replace(',',''))))\n",
    "total_act_pend_per_city = [int(num) for num in total_act_pend_per_city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:48:53.307813Z",
     "start_time": "2018-10-13T03:48:53.292079Z"
    }
   },
   "outputs": [],
   "source": [
    "city_name = []\n",
    "for num in prop_count_per_city_list:\n",
    "    for i in num:\n",
    "        city_name.extend((re.findall(r'in\\s(.+?)\\.', i['content'])))\n",
    "city_name = [num.replace(' New York', ' NY').replace(' Los Angeles', ' CA') for num in city_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:53:14.020069Z",
     "start_time": "2018-10-13T03:53:13.989715Z"
    }
   },
   "outputs": [],
   "source": [
    "act_pend_city_df = pd.DataFrame(columns=['city', 'tot_act_pend'])\n",
    "act_pend_city_df['city'] = city_name\n",
    "act_pend_city_df['tot_act_pend'] = total_act_pend_per_city\n",
    "act_pend_city_df['num_pgs'] = ((act_pend_city_df['tot_act_pend']//25)+1)\n",
    "act_pend_city_df.to_csv('../Data/act_pend_by_city.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:27:21.294955Z",
     "start_time": "2018-10-13T03:27:21.262741Z"
    }
   },
   "outputs": [],
   "source": [
    "def strip_count(lst):\n",
    "    lst = [str(num) for num in lst]\n",
    "    lst = [num.replace('[<meta content=\"Zillow has ', '') for num in lst]\n",
    "    lst = ap_prop_list = [num.replace(\n",
    "        '. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]', '') for num in lst]\n",
    "    lst = list(set(lst))\n",
    "    return lst\n",
    "\n",
    "new_prop_count_per_city_list = strip_count(prop_count_per_city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:27:38.726577Z",
     "start_time": "2018-10-13T03:27:38.709481Z"
    }
   },
   "outputs": [],
   "source": [
    "new_prop_count_per_city_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T03:27:23.588488Z",
     "start_time": "2018-10-13T03:27:23.497778Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_df_num_homes(prp_list):\n",
    "    re_all_num = r\"\\d+\\s\"\n",
    "    re_all_zip = r\"\\s\\d+\"\n",
    "\n",
    "    num_homes = []\n",
    "    zip_homes = []\n",
    "\n",
    "    for num in prp_list:\n",
    "        num_homes.append(re.findall(re_all_num, num))\n",
    "        zip_homes.append(re.findall(re_all_zip, num))\n",
    "\n",
    "    num_homes = [[int(y) for y in x] for x in num_homes]\n",
    "    zip_homes = [[int(y) for y in x] for x in zip_homes]\n",
    "\n",
    "    num_all_homes = []\n",
    "    zip_all_homes = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(prp_list):\n",
    "        num_all_homes.extend(num_homes[i])\n",
    "        zip_all_homes.extend(zip_homes[i])\n",
    "        i += 1\n",
    "\n",
    "    df = pd.DataFrame({\"all_homes\": num_all_homes}, index=zip_all_homes)\n",
    "    all_pages = [ceil(num/25) for num in df['all_homes']]\n",
    "    df['all_pages'] = all_pages\n",
    "    return df\n",
    "\n",
    "\n",
    "df_all = create_df_num_homes(new_prop_count_per_city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T02:44:30.616922Z",
     "start_time": "2018-10-13T02:44:30.597864Z"
    }
   },
   "outputs": [],
   "source": [
    "def zip_prop_count(zip_list, proxies, prp_list, ua, ezl):\n",
    "    proxy = random.sample(proxies, 1)[0]\n",
    "    print(proxies.index(proxy))\n",
    "    print(proxy)\n",
    "    for num in zip_list:\n",
    "        url = 'https://www.redfin.com/zipcode/' + \\\n",
    "            str(num) + '/filter/property-type=house+condo+townhouse,' + \\\n",
    "            'include=sold-1yr,min-price=100k,min-baths=1,include=sold-1yr'\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            soup = session_creator(proxy, ua, url)\n",
    "            print(num)\n",
    "            print(len(zip_list))\n",
    "            all_count = soup.findAll('div', {'class': 'homes summary'})\n",
    "            if len(str(all_count)) >= 20:\n",
    "                print(all_count)\n",
    "                print(time.time() - start_time)\n",
    "                ezl.append(num)\n",
    "                prp_list.append(all_count)\n",
    "                zip_list.remove(num)\n",
    "                print(len(zip_list) + len(prp_list))\n",
    "            else:\n",
    "                print(\"Captcha!!!!!\")\n",
    "        except:\n",
    "            print(\"Skipping. Connnection error\")\n",
    "            proxies.remove(proxy)\n",
    "            print(len(proxies))\n",
    "            return prp_list, zip_list, proxies, ezl\n",
    "    return prp_list, zip_list, proxies, ezl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T00:10:11.796348Z",
     "start_time": "2018-10-12T00:10:11.781094Z"
    }
   },
   "outputs": [],
   "source": [
    "def each_page(proxy, ua, url):\n",
    "    soup = session_creator(proxy, ua, url)\n",
    "    # start_time = time.time()\n",
    "    time.sleep(random.uniform(0, 1) * 3)\n",
    "    # print(time.time() - start_time)\n",
    "    full_soup = soup.findAll('a', {'class': 'bottom link-override'})\n",
    "    full_address = [fas['title'] for fas in full_soup]\n",
    "    home_link = ['https://www.redfin.com' +\n",
    "                 str(hls.get('href')) for hls in full_soup]\n",
    "    df = {'full_address': full_address, 'home_link': home_link}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T00:10:12.348231Z",
     "start_time": "2018-10-12T00:10:12.321405Z"
    }
   },
   "outputs": [],
   "source": [
    "def links_for_props(proxies, url_list, main_df, ua):\n",
    "    proxy = random.sample(proxies, 1)[0]\n",
    "    print(f'proxy number: {proxy}')\n",
    "    i = randint(0, (len(url_list) // 2))\n",
    "    print(f'starting from url number: {i}')\n",
    "    while i < len(url_list):\n",
    "        url = url_list[i]\n",
    "        try:\n",
    "            b = random.uniform(0.75, 2.25)\n",
    "            time.sleep(b)\n",
    "            # start_time = time.time()\n",
    "            # print(f'total left: {len(url_list)}')\n",
    "\n",
    "            data = each_page(proxy, ua, url)\n",
    "            df = pd.DataFrame(data)\n",
    "            eds = {'full_address': [], 'home_link': []}\n",
    "            if data['full_address'] != eds['full_address']:\n",
    "                main_df = pd.concat([main_df, df])\n",
    "                url_list.pop(i)\n",
    "                # a = (time.time() - start_time) * len(url_list)\n",
    "                # print('SUCCESS!!')\n",
    "                # print(f'Currently on url number: {i}')\n",
    "                # print(f'time taken: {a/len(url_list)}')\n",
    "                if i > 0:\n",
    "                    i -= randint(0, 1)\n",
    "                else:\n",
    "                    i += 0\n",
    "            else:\n",
    "                # print('No results')\n",
    "                # print(f'Currently on url number: {i}')\n",
    "                i += randint(1, 5)\n",
    "        except:\n",
    "            # print(\"Skipping. Connnection error\")\n",
    "            proxies.remove(proxy)\n",
    "            # print(f'proxies left: {len(proxies)}')\n",
    "            # print(f'total left: {len(url_list)}')\n",
    "            return url_list, main_df, proxies\n",
    "    return url_list, main_df, proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:21.017303Z",
     "start_time": "2018-10-11T20:42:21.003179Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.zillow.com/homedetails/895-Yakima-Dr-Fremont-CA-94539/25028455_zpid/?fullpage=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:22.435419Z",
     "start_time": "2018-10-11T20:42:21.763831Z"
    }
   },
   "outputs": [],
   "source": [
    "header = random.sample(ua, 1)[0]\n",
    "soup = session_creator(ua, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.150357Z",
     "start_time": "2018-10-11T20:54:02.106750Z"
    }
   },
   "outputs": [],
   "source": [
    "a = soup.findAll('div', {'class': 'fact-container'})\n",
    "b = soup.findAll('div', {'class': 'fact-value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.258818Z",
     "start_time": "2018-10-11T20:54:02.245098Z"
    }
   },
   "outputs": [],
   "source": [
    "z = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.412341Z",
     "start_time": "2018-10-11T20:54:02.396989Z"
    }
   },
   "outputs": [],
   "source": [
    "for num in a:\n",
    "    z.append(num.text)\n",
    "for num in b:\n",
    "    y.append(num.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.553016Z",
     "start_time": "2018-10-11T20:54:02.538843Z"
    }
   },
   "outputs": [],
   "source": [
    "z = [num.replace('  ','').replace('   ','').replace('\\r','').replace('\\n','').replace('\\xa0','') for num in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T21:01:14.174027Z",
     "start_time": "2018-10-11T21:01:14.147092Z"
    }
   },
   "outputs": [],
   "source": [
    "l = [re.findall(r'(.+)\\:', num) for num in z]\n",
    "# print(l)\n",
    "k = [re.findall(r'\\:(.+)', num) for num in z]\n",
    "# print(k)\n",
    "nd = {}\n",
    "i = 0\n",
    "while i < len(l):\n",
    "    if len(l[i])>0:\n",
    "        if l[i][0] in nd.keys():\n",
    "            nd[l[i][0]].extend(k[i])\n",
    "        else:\n",
    "            nd[l[i][0]] = k[i]\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1\n",
    "for k,v in nd.items():\n",
    "    nd[k] = ', '.join([num for num in v])\n",
    "print(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:46.056947Z",
     "start_time": "2018-10-11T20:42:46.039607Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [num.replace('  ','').replace('   ','').replace('\\r','').replace('\\n','').replace('\\xa0','') for num in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:46.645751Z",
     "start_time": "2018-10-11T20:42:46.629115Z"
    }
   },
   "outputs": [],
   "source": [
    "dict(zip(z,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
