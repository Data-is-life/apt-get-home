{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T02:50:35.598003Z",
     "start_time": "2018-10-12T02:50:35.580531Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import time, re, ast, sys, urllib, random, string, requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from selenium.webdriver.firefox.webdriver import FirefoxProfile\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError, URLError\n",
    "from itertools import cycle\n",
    "from header_list import user_agent_list\n",
    "from proxies_list import proxies_list_\n",
    "from INITIAL_SCRAPPER_FUNCTIONS import *\n",
    "from PARSER_FUNCTIONS import *\n",
    "from LIST_DF_FUNCTIONS import *\n",
    "from SEARCH_URL_GEN import *\n",
    "from GET_SEARCH_URL import *\n",
    "from GET_RESULTS import *\n",
    "ua = user_agent_list\n",
    "proxies = proxies_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T03:34:31.095995Z",
     "start_time": "2018-10-12T03:34:27.846276Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T02:52:28.726489Z",
     "start_time": "2018-10-12T02:52:28.710651Z"
    }
   },
   "outputs": [],
   "source": [
    "cities_url = pd.read_csv('../Data/city_url_search_list.csv', header=None)\n",
    "city_url_list = cities_url[0].tolist()\n",
    "# areas_list = [num for num in areas if str(num) != 'nan']\n",
    "city_url_list = random.sample(city_url_list, len(city_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T02:52:30.019285Z",
     "start_time": "2018-10-12T02:52:29.997856Z"
    }
   },
   "outputs": [],
   "source": [
    "under_prp_list = []\n",
    "prp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T02:50:37.873686Z",
     "start_time": "2018-10-12T02:50:37.853368Z"
    }
   },
   "outputs": [],
   "source": [
    "# url = 'https://www.zillow.com/homes/for_sale/Fremont-CA/fsba,fsbo,new_lt/house,condo,apartment_duplex,townhouse_type/11540_rid/1-_baths/20000-_price/83-_mp/50-_size/1_pnd/priced_sort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-12T03:36:55.035Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "50.224.173.189:8080\n",
      "[<meta content=\"Zillow has 749 homes for sale in Hialeah FL. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "4.0389933586120605\n",
      "63\n",
      "247\n",
      "36\n",
      "209.97.233.3:61268\n",
      "[<meta content=\"Zillow has 202 homes for sale in Burbank CA. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "4.3722779750823975\n",
      "62\n",
      "248\n",
      "37\n",
      "73.229.18.160:41062\n",
      "[<meta content=\"Zillow has 440 homes for sale in Poughkeepsie NY. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "8.907651424407959\n",
      "61\n",
      "249\n",
      "32\n",
      "47.210.133.169:43305\n",
      "[<meta content=\"Zillow has 1,420 homes for sale in Montgomery AL. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "10.026840448379517\n",
      "60\n",
      "250\n",
      "8\n",
      "64.19.116.82:60814\n",
      "[<meta content=\"Zillow has 1,311 homes for sale in Mobile AL. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "5.010510206222534\n",
      "59\n",
      "251\n",
      "9\n",
      "73.244.187.99:53281\n",
      "[<meta content=\"Zillow has 640 homes for sale in Henrico VA. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "41.935819149017334\n",
      "58\n",
      "252\n",
      "8\n",
      "64.19.116.82:60814\n",
      "[<meta content=\"Zillow has 845 homes for sale in Eugene OR. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "11.724746465682983\n",
      "57\n",
      "253\n",
      "32\n",
      "47.210.133.169:43305\n",
      "[<meta content=\"Zillow has 1,001 homes for sale in Bakersfield CA. View listing photos, review sales history, and use our detailed real estate filters to find the perfect place.\" name=\"description\"/>]\n",
      "9.598551034927368\n",
      "56\n",
      "254\n",
      "55\n",
      "104.236.55.48:8080\n",
      "[]\n",
      "6.711511850357056\n",
      "55\n",
      "255\n",
      "43\n",
      "166.130.163.233:34739\n"
     ]
    }
   ],
   "source": [
    "def areas_extractor_url(proxies, prp_list, url_list, ua):\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            proxy = random.sample(proxies, 1)[0]\n",
    "            print(proxies.index(proxy))\n",
    "            print(proxy)\n",
    "            start_time = time.time()\n",
    "            soup = session_creator(proxy, ua, url)\n",
    "            time.sleep(random.uniform(1.5,3.8))\n",
    "            all_count = soup.findAll('meta', {'name': 'description'})\n",
    "            print(all_count)\n",
    "            print(time.time() - start_time)\n",
    "            prp_list.append(all_count)\n",
    "            url_list.remove(url)\n",
    "            print(len(url_list))\n",
    "            print(len(prp_list))\n",
    "        except:\n",
    "            print(\"Skipping. Connnection error\")\n",
    "            proxies.remove(proxy)\n",
    "            print(len(proxies))\n",
    "            return prp_list, url_list\n",
    "    return prp_list, url_list\n",
    "\n",
    "\n",
    "prp_list, city_url_list = areas_extractor_url(\n",
    "    proxies, prp_list, city_url_list, ua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T03:27:56.587043Z",
     "start_time": "2018-10-12T03:27:56.572456Z"
    }
   },
   "outputs": [],
   "source": [
    "def session_creator(proxy, ua, url):\n",
    "    header = random.sample(ua, 1)[0]\n",
    "    session = requests.Session()\n",
    "    session.proxies = {\"http\": proxy, \"https\": proxy}\n",
    "    req = session.get(url, headers=header)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T00:10:11.294354Z",
     "start_time": "2018-10-12T00:10:11.269643Z"
    }
   },
   "outputs": [],
   "source": [
    "def zip_prop_count(zip_list, proxies, prp_list, ua, ezl):\n",
    "    proxy = random.sample(proxies, 1)[0]\n",
    "    print(proxies.index(proxy))\n",
    "    print(proxy)\n",
    "    for num in zip_list:\n",
    "        url = 'https://www.redfin.com/zipcode/' + \\\n",
    "            str(num) + '/filter/property-type=house+condo+townhouse,' + \\\n",
    "            'include=sold-1yr,min-price=100k,min-baths=1,include=sold-1yr'\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            soup = session_creator(proxy, ua, url)\n",
    "            print(num)\n",
    "            print(len(zip_list))\n",
    "            all_count = soup.findAll('div', {'class': 'homes summary'})\n",
    "            if len(str(all_count)) >= 20:\n",
    "                print(all_count)\n",
    "                print(time.time() - start_time)\n",
    "                ezl.append(num)\n",
    "                prp_list.append(all_count)\n",
    "                zip_list.remove(num)\n",
    "                print(len(zip_list) + len(prp_list))\n",
    "            else:\n",
    "                print(\"Captcha!!!!!\")\n",
    "        except:\n",
    "            print(\"Skipping. Connnection error\")\n",
    "            proxies.remove(proxy)\n",
    "            print(len(proxies))\n",
    "            return prp_list, zip_list, proxies, ezl\n",
    "    return prp_list, zip_list, proxies, ezl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T00:10:11.796348Z",
     "start_time": "2018-10-12T00:10:11.781094Z"
    }
   },
   "outputs": [],
   "source": [
    "def each_page(proxy, ua, url):\n",
    "    soup = session_creator(proxy, ua, url)\n",
    "    # start_time = time.time()\n",
    "    time.sleep(random.uniform(0, 1) * 3)\n",
    "    # print(time.time() - start_time)\n",
    "    full_soup = soup.findAll('a', {'class': 'bottom link-override'})\n",
    "    full_address = [fas['title'] for fas in full_soup]\n",
    "    home_link = ['https://www.redfin.com' +\n",
    "                 str(hls.get('href')) for hls in full_soup]\n",
    "    df = {'full_address': full_address, 'home_link': home_link}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T00:10:12.348231Z",
     "start_time": "2018-10-12T00:10:12.321405Z"
    }
   },
   "outputs": [],
   "source": [
    "def links_for_props(proxies, url_list, main_df, ua):\n",
    "    proxy = random.sample(proxies, 1)[0]\n",
    "    print(f'proxy number: {proxy}')\n",
    "    i = randint(0, (len(url_list) // 2))\n",
    "    print(f'starting from url number: {i}')\n",
    "    while i < len(url_list):\n",
    "        url = url_list[i]\n",
    "        try:\n",
    "            b = random.uniform(0.75, 2.25)\n",
    "            time.sleep(b)\n",
    "            # start_time = time.time()\n",
    "            # print(f'total left: {len(url_list)}')\n",
    "\n",
    "            data = each_page(proxy, ua, url)\n",
    "            df = pd.DataFrame(data)\n",
    "            eds = {'full_address': [], 'home_link': []}\n",
    "            if data['full_address'] != eds['full_address']:\n",
    "                main_df = pd.concat([main_df, df])\n",
    "                url_list.pop(i)\n",
    "                # a = (time.time() - start_time) * len(url_list)\n",
    "                # print('SUCCESS!!')\n",
    "                # print(f'Currently on url number: {i}')\n",
    "                # print(f'time taken: {a/len(url_list)}')\n",
    "                if i > 0:\n",
    "                    i -= randint(0, 1)\n",
    "                else:\n",
    "                    i += 0\n",
    "            else:\n",
    "                # print('No results')\n",
    "                # print(f'Currently on url number: {i}')\n",
    "                i += randint(1, 5)\n",
    "        except:\n",
    "            # print(\"Skipping. Connnection error\")\n",
    "            proxies.remove(proxy)\n",
    "            # print(f'proxies left: {len(proxies)}')\n",
    "            # print(f'total left: {len(url_list)}')\n",
    "            return url_list, main_df, proxies\n",
    "    return url_list, main_df, proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:21.017303Z",
     "start_time": "2018-10-11T20:42:21.003179Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.zillow.com/homedetails/895-Yakima-Dr-Fremont-CA-94539/25028455_zpid/?fullpage=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:22.435419Z",
     "start_time": "2018-10-11T20:42:21.763831Z"
    }
   },
   "outputs": [],
   "source": [
    "header = random.sample(ua, 1)[0]\n",
    "soup = session_creator(ua, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.150357Z",
     "start_time": "2018-10-11T20:54:02.106750Z"
    }
   },
   "outputs": [],
   "source": [
    "a = soup.findAll('div', {'class': 'fact-container'})\n",
    "b = soup.findAll('div', {'class': 'fact-value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.258818Z",
     "start_time": "2018-10-11T20:54:02.245098Z"
    }
   },
   "outputs": [],
   "source": [
    "z = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.412341Z",
     "start_time": "2018-10-11T20:54:02.396989Z"
    }
   },
   "outputs": [],
   "source": [
    "for num in a:\n",
    "    z.append(num.text)\n",
    "for num in b:\n",
    "    y.append(num.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:54:02.553016Z",
     "start_time": "2018-10-11T20:54:02.538843Z"
    }
   },
   "outputs": [],
   "source": [
    "z = [num.replace('  ','').replace('   ','').replace('\\r','').replace('\\n','').replace('\\xa0','') for num in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T21:01:14.174027Z",
     "start_time": "2018-10-11T21:01:14.147092Z"
    }
   },
   "outputs": [],
   "source": [
    "l = [re.findall(r'(.+)\\:', num) for num in z]\n",
    "# print(l)\n",
    "k = [re.findall(r'\\:(.+)', num) for num in z]\n",
    "# print(k)\n",
    "nd = {}\n",
    "i = 0\n",
    "while i < len(l):\n",
    "    if len(l[i])>0:\n",
    "        if l[i][0] in nd.keys():\n",
    "            nd[l[i][0]].extend(k[i])\n",
    "        else:\n",
    "            nd[l[i][0]] = k[i]\n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1\n",
    "for k,v in nd.items():\n",
    "    nd[k] = ', '.join([num for num in v])\n",
    "print(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:46.056947Z",
     "start_time": "2018-10-11T20:42:46.039607Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [num.replace('  ','').replace('   ','').replace('\\r','').replace('\\n','').replace('\\xa0','') for num in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:42:46.645751Z",
     "start_time": "2018-10-11T20:42:46.629115Z"
    }
   },
   "outputs": [],
   "source": [
    "dict(zip(z,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
